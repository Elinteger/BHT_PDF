{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeddd4b7",
   "metadata": {},
   "source": [
    "# PDF-Reduction\n",
    "\n",
    "This notebook explores a pipeline to identify and extract the most relevant pages of an application for the BHT Data Science Master's program using Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068181b0",
   "metadata": {},
   "source": [
    "# TODO: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aa4269",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613de7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- imports --\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pymupdf\n",
    "import torch\n",
    "from autogluon.multimodal import MultiModalPredictor\n",
    "import logging\n",
    "logging.getLogger(\"autogluon\").setLevel(logging.ERROR)\n",
    "\n",
    "# -- data paths --\n",
    "example_imgs = glob.glob('../data/imgs_labeled/color/76_*.jpg')  # 144 Pages\n",
    "# example_imgs = glob.glob('../data/imgs_labeled/color/1_*.jpg')  # 31 Pages\n",
    "output_example = '../data/reduced_pdfs/example.pdf'\n",
    "\n",
    "# -- config --\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "PRED_PATH = os.getenv(\"CLASSIFICATION_MODEL\")\n",
    "pred = MultiModalPredictor.load(f'../{PRED_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16fd9ab",
   "metadata": {},
   "source": [
    "## Classify relevant pages \n",
    "Looks for \"Stammdaten\", \"Zeugnisse\", \"Kursübersichten\" and labels them accordingly. Afterwards saves them in a PDF, including a table of contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d356df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIXME: check ORDER! sort, or be sure its sorted properly beforehand\n",
    "def reduce_pdf(images):\n",
    "    # predict and get idx\n",
    "    y_pred = pred.predict(images)\n",
    "\n",
    "    idx_dict = {}\n",
    "    idx_dict[\"Stammdaten\"] = np.where(y_pred == 'Stammdaten')[0].tolist()\n",
    "    idx_dict[\"Kursübersichten\" ] = np.where(y_pred == 'Kursübersicht')[0].tolist()\n",
    "    idx_dict[\"Zeugnisse\"] = np.where(y_pred == 'Zeugnis')[0].tolist()\n",
    "  \n",
    "    # create pdf\n",
    "    ## misc stuff needed for doc creation\n",
    "    p = pymupdf.Point(50, 842/2)\n",
    "    line_start = pymupdf.Point(p.x-10, p.y-25)   \n",
    "    line_end   = pymupdf.Point(p.x-10, p.y+5) \n",
    "    toc = []  # level, title, page\n",
    "\n",
    "    doc = pymupdf.open()\n",
    "\n",
    "    for name, idxs in idx_dict.items():\n",
    "        # create cover page\n",
    "        textpage = doc.new_page() \n",
    "        textpage.draw_line(line_start, line_end, width=3.5)\n",
    "        textpage.insert_text(\n",
    "            point=p,\n",
    "            text=name,\n",
    "            fontsize=30,\n",
    "        )\n",
    "        toc.append([1, name, doc.page_count])\n",
    "        for idx in idxs:\n",
    "            imgpage = doc.new_page()\n",
    "            imgpage.insert_image(\n",
    "                rect=imgpage.rect, \n",
    "                filename=images[idx],\n",
    "                keep_proportion=False # because images are always A4*200DPI\n",
    "            ) \n",
    "\n",
    "    doc.set_toc(toc=toc)\n",
    "    doc.save(output_example)\n",
    "\n",
    "   \n",
    "reduce_pdf(example_imgs) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
