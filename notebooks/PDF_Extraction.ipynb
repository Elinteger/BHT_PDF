{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94a2396e",
   "metadata": {},
   "source": [
    "# PDF-Extraction\n",
    "\n",
    "This notebooks holds a couple use case specific implementations to extract certain data out of PDF documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d10f095",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e42d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- imports --\n",
    "import os\n",
    "import pandas as pd\n",
    "import pymupdf\n",
    "import pymupdf4llm\n",
    "from bs4 import BeautifulSoup\n",
    "from docling.document_converter import DocumentConverter\n",
    "from io import StringIO\n",
    "from IPython.display import clear_output\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "from paddleocr import PaddleOCR\n",
    "from paddleocr import PPStructureV3\n",
    "from pydantic import BaseModel, RootModel\n",
    "from marker.models import create_model_dict\n",
    "from marker.output import text_from_rendered\n",
    "from marker.config.parser import ConfigParser\n",
    "from marker.converters.pdf import PdfConverter\n",
    "from typing import List, Literal\n",
    "\n",
    "# -- data paths --\n",
    "example_pdf = '../data/pdf_labeled/2.pdf'  # short document\n",
    "example_img = '../data/imgs_labeled/color/2_9.jpg'  # rather difficult example of same pdf as above\n",
    "\n",
    "# -- config --"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df518b2",
   "metadata": {},
   "source": [
    "## Extract text from machine-written documents\n",
    "\n",
    "Showcasing how to use three different tools for extraction of machine written PDF documents. \n",
    "\n",
    "If layout isn't terribly important PyMuPDF can be used for accurate extraction, otherwise either Docling aswell as Marker seem to offer good options for semi-structured extraction (HTML, MD).\n",
    "\n",
    "Most libraries have more functionality and config options than shown -> have a look into the respective docs before use!\n",
    "\n",
    "*... maybe also have a look at pyPDFIUM which seemingly has similar performance to PyMuPDF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d9ea0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_with_pymupdf(markdown=True):\n",
    "    if markdown:  # takes (10x) longer! \n",
    "        return pymupdf4llm.to_markdown(example_pdf)\n",
    "    else:\n",
    "        with pymupdf.open(example_pdf) as doc:\n",
    "            return chr(12).join([page.get_text() for page in doc])\n",
    "\n",
    "def extract_with_docling():\n",
    "    docling = DocumentConverter()\n",
    "    conv_result = docling.convert(example_pdf)\n",
    "    return conv_result.document.export_to_markdown()  # export_to_markdown() | export_to_html()\n",
    "\n",
    "def extract_with_marker():\n",
    "    config_no_llm = {\"output_format\":\"markdown\"}\n",
    "    config_llm = {\n",
    "        \"output_format\":\"markdown\",  # [markdown|json|html]\n",
    "        \"llm_service\": \"marker.services.ollama.OllamaService\",\n",
    "        \"use_llm\":True,\n",
    "        \"ollama_base_url\":\"http://localhost:11434\",  # ollama-default: \"http://localhost:11434\"\n",
    "        \"ollama_model\":\"gemma3:27b\",  \n",
    "        \"TableConverter_use_llm\":True,\n",
    "        # + prompts!\n",
    "    }\n",
    "    config_parser = ConfigParser(config_no_llm)\n",
    "\n",
    "    converter = PdfConverter(\n",
    "        config=config_parser.generate_config_dict(),\n",
    "        artifact_dict=create_model_dict(),\n",
    "        renderer=config_parser.get_renderer(),\n",
    "        processor_list=config_parser.get_processors(),\n",
    "        llm_service=config_parser.get_llm_service(),\n",
    "    )\n",
    "\n",
    "    conv_result = converter(example_pdf)\n",
    "    markdown_text, _, _ = text_from_rendered(conv_result) \n",
    "    return markdown_text\n",
    "\n",
    "\n",
    "pymu_result = extract_with_pymupdf()\n",
    "doc_result = extract_with_docling()\n",
    "mrk_result = extract_with_marker()\n",
    "\n",
    "clear_output() # clear logs from libraries\n",
    "\n",
    "print('PyMuPDF')\n",
    "print('-----------------------------------------------------------------')\n",
    "print(pymu_result)\n",
    "for i in range(3):\n",
    "    print('=================================================================')\n",
    "print('Docling')\n",
    "print('-----------------------------------------------------------------')\n",
    "print(doc_result)\n",
    "for i in range(3):\n",
    "    print('=================================================================')\n",
    "print('Marker')\n",
    "print('-----------------------------------------------------------------')\n",
    "print(mrk_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16540260",
   "metadata": {},
   "source": [
    "## Extract text from images using OCR\n",
    "\n",
    "While libraries like Docling also offer an OCR option, better results have been achieved with Paddle based tooling. If `use_structure=False` is set, uses a basic algorithm to create some rough structure.\n",
    "\n",
    "⚠️ Paddle-based models may not work in the notebook. Theres been a dependency issue going on with ipy-packages (ipykernel, ipywidgets) and paddlepaddle. Using the code in an external python file while running following commands to install the dependencies needed for PaddleOCR worked though:\n",
    "```\n",
    "pip install paddleocr[all]\n",
    "pip install paddlepaddle-gpu==3.2.0 -i https://www.paddlepaddle.org.cn/packages/stable/cu126/  # for an RTX 4090 with Cuda 12.7\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6efd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow the installation guide: https://www.paddleocr.ai/main/en/version3.x/installation.html\n",
    "\n",
    "class TextElement:\n",
    "    \"\"\"\n",
    "    Simple class to define a textelement and its bounding box coordinates obtained by performing OCR using PP-OCRv5.\n",
    "    \"\"\"\n",
    "    def __init__(self, text, top_left, bot_left, top_right, bot_right):\n",
    "        self.text = text\n",
    "        # Tuples; [0] = x-coordinate, [1] = y-coordinate\n",
    "        self.top_left = top_left\n",
    "        self.bot_left = bot_left\n",
    "        self.top_right = top_right\n",
    "        self.bot_right = bot_right\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"TextElement('{self.text}', with top left corner of bounding box at {self.top_left})\"\n",
    "\n",
    "\n",
    "def perform_OCR(use_structure=False):\n",
    "    if use_structure:\n",
    "        pipeline = PPStructureV3(text_recognition_model_name=\"en_PP-OCRv4_mobile_rec\",\n",
    "                                device=\"gpu\",\n",
    "                                use_doc_orientation_classify=True,\n",
    "                                use_doc_unwarping=False,\n",
    "                                use_textline_orientation=False,\n",
    "                                use_seal_recognition=True,\n",
    "                                use_table_recognition=True,\n",
    "                                use_formula_recognition=False,\n",
    "                                use_chart_recognition=False,\n",
    "                                use_region_detection=False)\n",
    "        output = pipeline.predict(example_img)\n",
    "        clear_output()\n",
    "\n",
    "        for res in output:\n",
    "             # res.save_to_markdown | json ()\n",
    "             res.print()\n",
    "    else:\n",
    "        ocr = PaddleOCR(lang='en', device='gpu')\n",
    "        text_elements: List[TextElement] = []\n",
    "        ocr_results = ocr.predict(example_img)\n",
    "        ocr_item = ocr_results[0] \n",
    "        # for each recognized text element (each \"box\" in the visual output of the OCR result) extract text and coordinates\n",
    "        for idx in range(len(ocr_results[0][\"rec_polys\"])):\n",
    "            box_coords = ocr_item[\"rec_polys\"][idx]\n",
    "            text = ocr_item[\"rec_texts\"][idx]\n",
    "\n",
    "            if text.strip():  # if text not empty\n",
    "                top_left = tuple(box_coords[0])\n",
    "                bot_left = tuple(box_coords[3])\n",
    "                top_right = tuple(box_coords[1])\n",
    "                bot_right = tuple(box_coords[2])\n",
    "\n",
    "                text_elements.append(TextElement(text,top_left, bot_left, top_right, bot_right))\n",
    "        # post-process to create formatted string\n",
    "        text = \"\"\n",
    "        for i, element in enumerate(text_elements):\n",
    "            text += element.text.strip()\n",
    "\n",
    "            if i + 1 >= len(text_elements):\n",
    "                continue\n",
    "            # check if next text is on similar height, if not -> \\n\n",
    "            elif vertical_overlap_ratio(element, text_elements[i + 1]) <= 0.75:  # if needed, tweak ratio threshold\n",
    "                text += '\\n'\n",
    "            else:\n",
    "                text += '\\t' \n",
    "                \n",
    "        clear_output()\n",
    "        print(text)\n",
    "    \n",
    "\n",
    "def vertical_overlap_ratio(e1, e2):\n",
    "    \"\"\"\n",
    "    Simple function to compute the ratio of vertical overlap of two bounding boxes. \n",
    "    \"\"\"\n",
    "    # get biggest possible vertical line of both boxes\n",
    "    top1 = min(e1.top_left[1], e1.top_right[1])\n",
    "    bot1 = max(e1.bot_left[1], e1.bot_right[1])\n",
    "    top2 = min(e2.top_left[1], e2.top_right[1])\n",
    "    bot2 = max(e2.bot_left[1], e2.bot_right[1])\n",
    "\n",
    "    # find intersection\n",
    "    overlap_top = max(top1, top2)\n",
    "    overlap_bot = min(bot1, bot2)\n",
    "    overlap_height = max(0, overlap_bot - overlap_top)\n",
    "\n",
    "    # find smallest height to normalize\n",
    "    height1 = bot1 - top1\n",
    "    height2 = bot2 - top2\n",
    "\n",
    "    min_height = min(height1, height2)\n",
    "    if min_height == 0:\n",
    "        return 0 \n",
    "    \n",
    "    return overlap_height / min_height\n",
    "\n",
    "# PPStruct v3 doesn't work due to a dependency missing(?)\n",
    "perform_OCR(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9012a1c",
   "metadata": {},
   "source": [
    "## Extract Stammdaten\n",
    "\n",
    "Example on how to extract relevant data with a rule-based approach from pages that keep the exact same layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using marker to extract text in HTML (a PDF-Reader that transforms to HTML could work aswell though!)\n",
    "\n",
    "config = {\n",
    "    'output_format':'html',\n",
    "    'page_range':'0'  # TODO: replace with Stammdaten page if used\n",
    "}\n",
    "\n",
    "config_parser = ConfigParser(config)\n",
    "\n",
    "converter = PdfConverter(\n",
    "    config=config_parser.generate_config_dict(),\n",
    "    artifact_dict=create_model_dict(),\n",
    "    renderer=config_parser.get_renderer(),\n",
    "    processor_list=config_parser.get_processors(),\n",
    "    llm_service=config_parser.get_llm_service(),\n",
    ")\n",
    "\n",
    "base = converter(example_pdf)\n",
    "html_txt, _, _ = text_from_rendered(base)\n",
    "\n",
    "## use bs4 to edit HTML and create dictionary\n",
    "soup = BeautifulSoup(html_txt, 'html.parser')\n",
    "# swap <br/> tags with spaces\n",
    "for br in soup.find_all('br'):\n",
    "    br.replace_with(' ')\n",
    "# normalize text in <th> tags by removing linebreaks\n",
    "for th in soup.find_all(\"th\"):\n",
    "    th.string = \" \".join(th.get_text(strip=True, separator=\" \").split())\n",
    "# create dictionary out of normalized html \n",
    "stammdaten = {}\n",
    "rows = soup.find_all('tr')\n",
    "for row in rows:\n",
    "    cells = row.find_all('th')\n",
    "    if len(cells) >= 2:\n",
    "        for i in range(0, len(cells) - 1, 2):\n",
    "            key = cells[i].get_text(strip=True)\n",
    "            value = cells[i+1].get_text(strip=True)\n",
    "            if key:  # avoid empty keys\n",
    "                stammdaten[key] = value\n",
    "\n",
    "# remove output of marker\n",
    "clear_output()  \n",
    "\n",
    "# print(stammdaten)\n",
    "print(f\"Name: {stammdaten['Vorname']} {stammdaten['Nachname']}\")  # example output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4652e55",
   "metadata": {},
   "source": [
    "## Extract Kursübersicht\n",
    "\n",
    "Example on how to extract relevant data with a LLM approach from pages that differ in their layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd70a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: \n",
    "# Using PP-StructureV3 for now as it usually gives better results. \n",
    "# Using the MarkDown output as the HTML output remains empty if there are no tables.\n",
    "# Using OCR in any case, as the tables we got here are usually photos of documents.\n",
    "example_img = './data/imgs_labeled/color/2_9.jpg'\n",
    "pipeline = PPStructureV3(text_recognition_model_name=\"en_PP-OCRv4_mobile_rec\",\n",
    "                        device=\"gpu\",\n",
    "                        use_doc_orientation_classify=True,\n",
    "                        use_doc_unwarping=True,\n",
    "                        use_textline_orientation=False,\n",
    "                        use_seal_recognition=True,\n",
    "                        use_table_recognition=True,\n",
    "                        use_formula_recognition=False,\n",
    "                        use_chart_recognition=False,\n",
    "                        use_region_detection=True\n",
    "                        )\n",
    "\n",
    "output = pipeline.predict(example_img)\n",
    "\n",
    "html = output[0].markdown['markdown_texts']  # return htmls and md hybrid\n",
    "\n",
    "# define output format\n",
    "class Course(BaseModel):\n",
    "    academic_field: Literal[\"Computer Science\", \"Mathematics\"]\n",
    "    course_name: str\n",
    "    awarded_credits: float\n",
    "class Courses(RootModel[List[Course]]):\n",
    "    pass\n",
    "\n",
    "response: ChatResponse = chat(\n",
    "    model='gemma3:27b',  # TODO: try qwen 3\n",
    "    messages=[\n",
    "         {\n",
    "            'role': 'user',\n",
    "            'content': f\"\"\"\n",
    "                You are given an HTML representation of a scanned page. \n",
    "                1. Determine if it is an academic record or transcript showing a single student's grades and/or earned credits. \n",
    "                2. If yes, identify all courses whose subject matter falls under the academic fields of \"Computer Science\" or \"Mathematics\" — this includes courses that are clearly related even if the document does not use those exact headings. Use your judgment to classify them based on their titles, descriptions, or course codes. \n",
    "                3. If it is not an academic record or transcript, return no results.\n",
    "                Here is the HTML: \n",
    "                {html}\n",
    "            \"\"\"\n",
    "        }\n",
    "    ],\n",
    "    format=Courses.model_json_schema()\n",
    ")\n",
    "\n",
    "print(pd.read_json(StringIO(response['message']['content'])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
